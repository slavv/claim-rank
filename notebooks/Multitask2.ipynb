{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/slav/ai/claim-rank\n"
     ]
    }
   ],
   "source": [
    "%cd /home/slav/ai/claim-rank\n",
    "!export PYTHONPATH=.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42) # ! before importing keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data.debates import read_debates, Debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.features.feature_sets import get_cb_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Conv1D, Dense\n",
    "from keras.models import Model, clone_model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import optimizers\n",
    "from src.stats.rank_metrics import average_precision, precision_at_n, accuracy_rounded\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing.data import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokens_num', 'text_len', 'bag_tfidf', 'pos']\n"
     ]
    }
   ],
   "source": [
    "train_sentences = read_debates(Debate.FIRST) + read_debates(Debate.VP)\n",
    "val_sentences = read_debates(Debate.SECOND)\n",
    "test_sentences = read_debates(Debate.THIRD)\n",
    "\n",
    "pipeline = get_cb_pipeline(train=train_sentences)\n",
    "X_train = pipeline.fit_transform(train_sentences)\n",
    "X_val = pipeline.fit_transform(val_sentences)\n",
    "X_test = pipeline.transform(test_sentences)\n",
    "\n",
    "y_train_pf = np.array([int(s.labels[5]) for s in train_sentences])\n",
    "y_train_all = np.array([1 if s.label>0 else 0 for s in train_sentences])\n",
    "\n",
    "y_val_pf = np.array([int(s.labels[5]) for s in val_sentences])\n",
    "y_val_all = np.array([1 if s.label>0 else 0 for s in val_sentences])\n",
    "\n",
    "y_test_pf = np.array([int(s.labels[5]) for s in test_sentences])\n",
    "y_test_all = np.array([1 if s.label>0 else 0 for s in test_sentences])\n",
    "\n",
    "\n",
    "y_train_0 = np.array([int(s.labels[0]) for s in train_sentences])\n",
    "y_train_1 = np.array([int(s.labels[1]) for s in train_sentences])\n",
    "y_train_2 = np.array([int(s.labels[2]) for s in train_sentences])\n",
    "y_train_3 = np.array([int(s.labels[3]) for s in train_sentences])\n",
    "y_train_4 = np.array([int(s.labels[4]) for s in train_sentences])\n",
    "y_train_5 = np.array([int(s.labels[5]) for s in train_sentences])\n",
    "y_train_6 = np.array([int(s.labels[6]) for s in train_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2761, 1363)\n",
      "['0', '0', '1', '0', '0', '0', '0', '0', '0']\n",
      "1\n",
      "1363\n",
      "(2761,)\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(train_sentences[103].labels)\n",
    "print(train_sentences[103].label)\n",
    "print(X_train.shape[1])\n",
    "print(np.array(y_train_all).shape)\n",
    "print(y_val_pf[13])\n",
    "print(y_val_all[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_count = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_baseline_model(out_count):\n",
    "    input_layer = Input(shape=(features_count,))\n",
    "    x = Dense(features_count, kernel_initializer='normal', activation='relu')(input_layer)\n",
    "    \n",
    "    outputs = list(map(lambda _: Dense(1, kernel_initializer='normal', activation='sigmoid')(x), range(out_count)))\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=outputs)\n",
    "                         \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_single_model(train_target, label_func, iters = 20, epochs=5):\n",
    "    model = create_baseline_model(1);\n",
    "\n",
    "    best_model = None;\n",
    "    best_av_p = 0.;\n",
    "    best_epoch = -1;\n",
    "\n",
    "    for epoch in range(iters):\n",
    "        \n",
    "        model.fit(X_train, y=[train_target], epochs=epochs, verbose=0, batch_size=550)\n",
    "\n",
    "        predicted_val = model.predict(X_val)\n",
    "        \n",
    "        for pred, sentence in zip(predicted_val, val_sentences):\n",
    "            sentence.pred = pred[0]\n",
    "\n",
    "        av_p = average_precision(val_sentences,1, label_func)\n",
    "        \n",
    "        print(str(epoch) + ':' + str(av_p) + ' ', end='')\n",
    "        \n",
    "        if (av_p > best_av_p):\n",
    "            best_model = clone_model(model);\n",
    "            best_av_p = av_p;\n",
    "            best_epoch = epoch;\n",
    "    \n",
    "    print()\n",
    "\n",
    "    print(best_av_p)\n",
    "    print((best_epoch + 1) * epochs)\n",
    "\n",
    "    predicted_val = best_model.predict(X_test)\n",
    "    for pred, sentence in zip(predicted_val, test_sentences):\n",
    "        sentence.pred = pred[0]\n",
    "\n",
    "    print(average_precision(test_sentences,1,label_func))\n",
    "    \n",
    "    return [best_model, best_av_p, best_epoch]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_multiple_model(train_targets, iters = 20, epochs=5):\n",
    "    model = create_baseline_model(len(train_targets));\n",
    "\n",
    "    best_model = None;\n",
    "    best_av_p = 0.;\n",
    "    best_epoch = -1;\n",
    "\n",
    "    best_model_all = None;\n",
    "    best_av_p_all = 0.;\n",
    "    best_epoch_all = -1;\n",
    "\n",
    "    for epoch in range(iters):\n",
    "        model.fit(X_train, y=train_targets, epochs=epochs, verbose=0, batch_size=550)\n",
    "\n",
    "        predicted_val = model.predict(X_val)\n",
    "        \n",
    "        for pred, sentence in zip(predicted_val[1], val_sentences):\n",
    "            sentence.pred = pred[0]\n",
    "\n",
    "        av_p = average_precision(val_sentences,1, lambda x: x.labels[5])\n",
    "        \n",
    "        print(str(epoch) + ':' + str(av_p) + ' ', end='')\n",
    "        \n",
    "        if (av_p > best_av_p):\n",
    "            best_model = clone_model(model);\n",
    "            best_av_p = av_p;\n",
    "            best_epoch = epoch;\n",
    "\n",
    "        for pred, sentence in zip(predicted_val[0], val_sentences):\n",
    "            sentence.pred = pred[0]\n",
    "\n",
    "        av_p_all = average_precision(val_sentences,1)\n",
    "        if (av_p_all > best_av_p_all):\n",
    "            best_model_all = clone_model(model);\n",
    "            best_av_p_all = av_p_all;\n",
    "            best_epoch_all = epoch;\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('All:')\n",
    "    print(best_av_p_all)\n",
    "    print((best_epoch_all+ 1) * epochs)\n",
    "\n",
    "    predicted_val = best_model_all.predict(X_test)\n",
    "    for pred, sentence in zip(predicted_val[0], test_sentences):\n",
    "        sentence.pred = pred[0]\n",
    "\n",
    "    print(average_precision(test_sentences,1))\n",
    "\n",
    "    print('Pf:')\n",
    "    print(best_av_p)\n",
    "    print((best_epoch + 1) * epochs)\n",
    "\n",
    "    predicted_val = best_model.predict(X_test)\n",
    "    for pred, sentence in zip(predicted_val[1], test_sentences):\n",
    "        sentence.pred = pred[0]\n",
    "\n",
    "    print(average_precision(test_sentences,1,lambda x: x.labels[5]))\n",
    "    \n",
    "    return [[best_model, best_av_p, best_epoch], [best_model_all, best_av_p_all, best_epoch_all]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0.08568362776319396 1:0.0841058544893181 2:0.08327489554230191 3:0.08465425209502174 4:0.08520665391177969 5:0.08558767514325119 6:0.0858612471152793 7:0.08608524650149238 8:0.08477297324612136 9:0.08456764089679783 10:0.08489820980096813 11:0.08572801403180297 12:0.0837582979655827 13:0.0849257061782979 14:0.08430671644968105 15:0.08350463210940727 16:0.08388878088547444 17:0.08327481061547667 18:0.08440377336356614 19:0.08502413122360596 \n",
      "0.08608524650149238\n",
      "40\n",
      "0.03760844293588806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7f65090ede48>, 0.08608524650149238, 7]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_single_model(y_train_pf, lambda x: x.labels[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0:0.04049282159721163 1 1:0.06176059174088208 2 2:0.07245641306015117 3 3:0.0796399638736438 4 4:0.08254168387207181 5 5:0.07764345619829341 6 6:0.07782296228799981 7 7:0.08029625947806485 8 8:0.08009007491456578 9 9:0.08002146038208462 10 10:0.08072669389409588 11 11:0.07954248148944153 12 12:0.08157952872338953 13 13:0.08003625558159179 14 14:0.07679120993505488 15 15:0.07567183805929156 16 16:0.07955342810216454 17 17:0.07907411439449379 18 18:0.07900856703621333 19 19:0.07918662014610028 \n",
      "All:\n",
      "0.2873262760389052\n",
      "10\n",
      "0.2635333672595357\n",
      "Pf:\n",
      "0.08254168387207181\n",
      "25\n",
      "0.03517072207960124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[<keras.engine.training.Model at 0x7f64f3cd0668>, 0.08254168387207181, 4],\n",
       " [<keras.engine.training.Model at 0x7f64f3dea748>, 0.2873262760389052, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_multiple_model([y_train_all, y_train_pf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
